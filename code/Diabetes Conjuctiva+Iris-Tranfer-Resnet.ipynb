{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "t9ZS8RruhIpL"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sami\\anaconda3\\lib\\site-packages (4.8.0.74)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sami\\anaconda3\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def get_images(directory):\n",
    "    Images = []\n",
    "    Labels = []  # 0 non_diabetic , 1 for diabetic\n",
    "    for labels in os.listdir(directory): \n",
    "        for image_file in os.listdir(directory+labels): \n",
    "            image = cv2.imread(directory+labels+r'/'+image_file) \n",
    "            image = cv2.resize(image,(224,224)) \n",
    "            Images.append(image)\n",
    "            Labels.append(labels)\n",
    "    return shuffle(Images,Labels,random_state=817328462)\n",
    "\n",
    "ImagesC, LabelsC = get_images(\"Data\\\\Conjuctiva\\\\\")\n",
    "ImagesC = np.array(ImagesC)\n",
    "LabelsC = np.array(LabelsC)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "YC = np.array(label_encoder.fit_transform(LabelsC))\n",
    "\n",
    "ImagesI, LabelsI = get_images(\"Data\\\\Iris - Small\\\\\")\n",
    "ImagesI = np.array(ImagesI)\n",
    "LabelsI = np.array(LabelsI)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "YI = np.array(label_encoder.fit_transform(LabelsI))\n",
    "\n",
    "combined_features = np.concatenate((ImagesC, ImagesI), axis=0)\n",
    "combined_labels = np.concatenate((YC, YI), axis=0)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, combined_labels, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 10s 0us/step\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.78488, saving model to best_model.h5\n",
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.78488\n",
      "\n",
      "Epoch 3: val_accuracy did not improve from 0.78488\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.78488 to 0.80233, saving model to best_model.h5\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.80233 to 0.80814, saving model to best_model.h5\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.80814 to 0.83721, saving model to best_model.h5\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.83721 to 0.84302, saving model to best_model.h5\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.84302\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.84302\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.84302\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.84302 to 0.86047, saving model to best_model.h5\n",
      "\n",
      "Epoch 12: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 27: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 30: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.86047\n",
      "\n",
      "Epoch 32: val_accuracy improved from 0.86047 to 0.87791, saving model to best_model.h5\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 48: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 51: val_accuracy did not improve from 0.87791\n",
      "\n",
      "Epoch 52: val_accuracy improved from 0.87791 to 0.88372, saving model to best_model.h5\n",
      "\n",
      "Epoch 53: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 54: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 56: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 58: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 59: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 61: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 62: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 63: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 68: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 69: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 70: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 71: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 73: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 74: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 75: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 76: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 79: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 80: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 81: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 82: val_accuracy did not improve from 0.88372\n",
      "\n",
      "Epoch 83: val_accuracy improved from 0.88372 to 0.89535, saving model to best_model.h5\n",
      "\n",
      "Epoch 84: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 85: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 86: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 88: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 89: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 90: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 91: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 92: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 93: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 94: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 95: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 96: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 98: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 99: val_accuracy did not improve from 0.89535\n",
      "\n",
      "Epoch 100: val_accuracy did not improve from 0.89535\n",
      "6/6 [==============================] - 7s 1s/step\n",
      "Test Accuracy: 89.535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        90\n",
      "           1       0.89      0.89      0.89        82\n",
      "\n",
      "    accuracy                           0.90       172\n",
      "   macro avg       0.90      0.90      0.90       172\n",
      "weighted avg       0.90      0.90      0.90       172\n",
      "\n",
      "[[81  9]\n",
      " [ 9 73]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# load model without classifier layers\n",
    "base_model = ResNet50(include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers in base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(base_model.output)\n",
    "class1 = Dense(1024, activation='relu')(flat1)\n",
    "dropout1 = Dropout(0.5)(class1)\n",
    "class2 = Dense(1024, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(0.5)(class2)\n",
    "output = Dense(2, activation='softmax')(dropout2)\n",
    "\n",
    "# define new model\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n",
    "\n",
    "# compile model\n",
    "opt = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Early stopping and model checkpointing\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(datagen.flow(X_train, y_train_cat, batch_size=32), \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    epochs=100, verbose=0, callbacks=[es, mc])\n",
    "\n",
    "# load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "saved_model = load_model('best_model.h5')\n",
    "\n",
    "# predict\n",
    "y_pred = saved_model.predict(X_test)\n",
    "\n",
    "# convert probabilities to class labels\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# evaluate model\n",
    "_, acc = saved_model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "print('Test Accuracy: %.3f' % (acc * 100.0))\n",
    "\n",
    "# classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cancer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
