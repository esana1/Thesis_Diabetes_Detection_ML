{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ItgG_U8G3ZLK"
   },
   "outputs": [],
   "source": [
    "import sys, cv2, glob, os, time\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "# importing all necessary libraries to run the code\n",
    "import re,string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "t9ZS8RruhIpL"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_images(directory):\n",
    "\n",
    "    Images = []\n",
    "\n",
    "    Labels = []  # 0 for Building , 1 for forest, 2 for glacier, 3 for mountain, 4 for Sea , 5 for Street\n",
    "\n",
    "    for labels in os.listdir(directory): #Main Directory where each class label is present as folder name.   \n",
    "\n",
    "        for image_file in os.listdir(directory+labels): #Extracting the file name of the image from Class Label folder\n",
    "\n",
    "            image = cv2.imread(directory+labels+r'/'+image_file) #Reading the image (OpenCV)\n",
    "\n",
    "            image = cv2.resize(image,(150,150)) #Resize the image, Some images are different sizes. (Resizing is very Important)\n",
    "\n",
    "            Images.append(image)\n",
    "\n",
    "            Labels.append(labels)\n",
    "\n",
    "    return shuffle(Images,Labels,random_state=817328462) #Shuffle the dataset you just prepared.\n",
    "\n",
    "#Train data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagesC, LabelsC = get_images(\"C:\\\\Users\\\\knowl\\\\Downloads\\\\Diabetes\\\\Data\\\\Conjuctiva\\\\\") #Extract the training images from the folders.\n",
    "\n",
    "ImagesC = np.array(ImagesC) #converting the list of images to numpy array.\n",
    "\n",
    "LabelsC = np.array(LabelsC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'non_diabetic': 286, 'diabetic': 286})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(LabelsC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samplesC = len(ImagesC)\n",
    "data_imagesRGBC = ImagesC.reshape((n_samplesC, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "YC = np.array(label_encoder.fit_transform(LabelsC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 286, 0: 286})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(YC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImagesI, LabelsI = get_images(\"C:\\\\Users\\\\knowl\\\\Downloads\\\\Diabetes\\\\Data\\\\Iris\\\\\") #Extract the training images from the folders.\n",
    "\n",
    "ImagesI = np.array(ImagesI) #converting the list of images to numpy array.\n",
    "\n",
    "LabelsI = np.array(LabelsI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'diabetic': 400, 'non_diabetic': 400})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(LabelsI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samplesI = len(ImagesI)\n",
    "data_imagesRGBI = ImagesI.reshape((n_samplesI, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "YI = np.array(label_encoder.fit_transform(LabelsI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 400, 1: 400})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(YI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_imagesRGBI, YI, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Training Using Iris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75        52\n",
      "           1       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.77      0.78      0.77       120\n",
      "weighted avg       0.78      0.78      0.78       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "print(\"SVC\")\n",
    "svm = SVC(kernel='linear', C=3.0, random_state=42)\n",
    "svm.fit(X_train,y_train)\n",
    "y_pred=svm.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Training Using Conjuctiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(data_imagesRGBC, YC, test_size=0.15, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.47674418604651164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.87      0.59        38\n",
      "           1       0.62      0.17      0.26        48\n",
      "\n",
      "    accuracy                           0.48        86\n",
      "   macro avg       0.53      0.52      0.43        86\n",
      "weighted avg       0.54      0.48      0.41        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "print(\"SVC\")\n",
    "svm1 = SVC(kernel='linear', C=3.0, random_state=42)\n",
    "svm1.fit(X_train1,y_train1)\n",
    "y_pred1=svm.predict(X_test1)\n",
    "print(accuracy_score(y_test1,y_pred1))\n",
    "print(classification_report(y_test1,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Testing using Conjuctiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined SVM Classifier Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73        38\n",
      "           1       0.77      0.85      0.81        48\n",
      "\n",
      "    accuracy                           0.78        86\n",
      "   macro avg       0.78      0.77      0.77        86\n",
      "weighted avg       0.78      0.78      0.78        86\n",
      "\n",
      "Combined SVM Classifier Accuracy: [[26 12]\n",
      " [ 7 41]]\n"
     ]
    }
   ],
   "source": [
    "def combine_predictions(predictions1, predictions2):\n",
    "    combined_predictions = []\n",
    "    for p1, p2 in zip(predictions1, predictions2):\n",
    "        # Convert predictions to integers for majority voting\n",
    "        combined_predictions.append(np.sign(int(p1) + int(p2)))\n",
    "    return combined_predictions\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions using the trained classifiers\n",
    "predictions1 = svm.predict(X_test1)\n",
    "predictions2 = svm1.predict(X_test1)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "combined_predictions = combine_predictions(predictions1, predictions2)\n",
    "\n",
    "# Calculate accuracy of the combined predictions\n",
    "accuracy = classification_report(y_test1, combined_predictions)\n",
    "print(\"Combined SVM Classifier Accuracy:\", accuracy)\n",
    "\n",
    "accuracy = confusion_matrix(y_test1, combined_predictions)\n",
    "print(\"Combined SVM Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Testing using Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined SVM Classifier Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.79      0.75        52\n",
      "           1       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.78       120\n",
      "   macro avg       0.77      0.78      0.77       120\n",
      "weighted avg       0.78      0.78      0.78       120\n",
      "\n",
      "Combined SVM Classifier Accuracy: [[41 11]\n",
      " [16 52]]\n"
     ]
    }
   ],
   "source": [
    "def combine_predictions(predictions1, predictions2):\n",
    "    combined_predictions = []\n",
    "    for p1, p2 in zip(predictions1, predictions2):\n",
    "        # Convert predictions to integers for majority voting\n",
    "        combined_predictions.append(np.sign(int(p1) + int(p2)))\n",
    "    return combined_predictions\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions using the trained classifiers\n",
    "predictions1 = svm.predict(X_test)\n",
    "predictions2 = svm1.predict(X_test)\n",
    "\n",
    "# Combine predictions using majority voting\n",
    "combined_predictions = combine_predictions(predictions1, predictions2)\n",
    "\n",
    "# Calculate accuracy of the combined predictions\n",
    "accuracy = classification_report(y_test, combined_predictions)\n",
    "print(\"Combined SVM Classifier Accuracy:\", accuracy)\n",
    "\n",
    "accuracy = confusion_matrix(y_test, combined_predictions)\n",
    "print(\"Combined SVM Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined SVM Classifier Accuracy:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60        52\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.43       120\n",
      "   macro avg       0.22      0.50      0.30       120\n",
      "weighted avg       0.19      0.43      0.26       120\n",
      "\n",
      "Combined SVM Classifier Accuracy: [[52  0]\n",
      " [68  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\knowl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\knowl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\knowl\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Train SVM classifiers on each dataset\n",
    "\n",
    "# Train SVM classifier on dataset1\n",
    "svm_classifier1 = svm.SVC(kernel='linear', C=3.0, probability=True)  # Set probability=True for soft voting\n",
    "svm_classifier1.fit(X_train, y_train)\n",
    "\n",
    "# Train SVM classifier on dataset2\n",
    "svm_classifier2 = svm.SVC(kernel='linear', C=3.0, probability=True)  # Set probability=True for soft voting\n",
    "svm_classifier2.fit(X_train1, y_train1)\n",
    "\n",
    "# Step 2: Combine classifiers for soft voting\n",
    "\n",
    "def combine_predictions_soft(predictions1, predictions2):\n",
    "    combined_predictions = []\n",
    "    for p1, p2 in zip(predictions1, predictions2):\n",
    "        # Soft voting: average the probabilities from both classifiers\n",
    "        avg_probabilities = (p1 + p2) / 2\n",
    "        combined_predictions.append(np.argmax(avg_probabilities))  # Use the class with the highest probability\n",
    "    return combined_predictions\n",
    "\n",
    "# Step 3: Make predictions on the test data\n",
    "\n",
    "# Assuming you have test data for both datasets named 'test_data1' and 'test_data2'\n",
    "# Replace 'test_data1' and 'test_data2' with the appropriate test data\n",
    "\n",
    "# Get class probabilities from the trained classifiers\n",
    "probabilities1 = svm_classifier1.predict_proba(X_test)\n",
    "probabilities2 = svm_classifier2.predict_proba(X_test)\n",
    "\n",
    "# Combine predictions using soft voting\n",
    "combined_predictions = combine_predictions_soft(probabilities1, probabilities2)\n",
    "\n",
    "# Step 4: Evaluate the combined predictions\n",
    "\n",
    "# Assuming you have true labels for the test data named 'true_labels'\n",
    "# Replace 'true_labels' with the appropriate true labels\n",
    "\n",
    "# Calculate accuracy of the combined predictions\n",
    "accuracy = classification_report(y_test, combined_predictions)\n",
    "print(\"Combined SVM Classifier Accuracy:\", accuracy)\n",
    "\n",
    "accuracy = confusion_matrix(y_test, combined_predictions)\n",
    "print(\"Combined SVM Classifier Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cancer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
